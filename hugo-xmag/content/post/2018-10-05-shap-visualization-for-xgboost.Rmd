---
title: 'SHAP Visualization for XGBoost'
author: Yang Liu
date: '2018-10-14'
slug: shap-visualization-for-xgboost
categories:
  - Machine Learning
  - Data Visualization
tags:
  - XGBoost
  - SHAP
output:
  blogdown::html_page:
    toc: true
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```
(Under further revise)

# Background
I will illustrate the application of SHAP (SHapley Additive exPlnation) values to visualize the efforts of features on the outcome variable in a XGBoost model.  
The function was developed by [_Scott Lundberg_ in Python and explained here](https://github.com/slundberg/shap). SHAP was combined into _xgboost_ with one visualization function _xgb.plot.shap_. But we can make better summary figures as in the Python package in more flexible ways by extracting the SHAP values. 

```{r libs, include = FALSE}
# Column Water Vapor correction - Modified script for correcting AOD measurements 
# The original script is 07_feature_selection_MOD1a.R, also included in this repo.
library(autoxgboost) # for auto xgboost
library(googledrive)
library(data.table)
library(xgboost)
library(ggforce)
library(ggplot2)
options(digits = 4)

# Data Preparation using data.table -----------------------------
# https://drive.google.com/open?id=1pHE8ktykKfBN2_yo8FNxYX_BFKp1S0SN
id <- "1pHE8ktykKfBN2_yo8FNxYX_BFKp1S0SN" # google file ID
mydata <- fread(sprintf("https://docs.google.com/uc?id=%s&export=download", id),
                stringsAsFactors = TRUE)

# clean variables names, remove "/".
names(mydata) <- gsub("/", "", names(mydata)) 

# create variable: Share_Temporary
# The dependent variable to be modeled: Share of temporary structure in slums
mydata[, Share_Temporary := CC7_Structures_Temporary / (CC7_Structures_Temporary + CC6_Structures_Permanent)]

# remove variables with over 20% NA, var_keeps those is.na < 20%
var_keep <- sapply(mydata, function(x) sum(is.na(x))) < dim(mydata)[1]*0.2
var_keep[length(var_keep)] <- TRUE # keep "Share_Temporary"
mydata[, names(mydata)[!var_keep]:= NULL]
mydata <- na.omit(mydata) # remove rest N.A.
# fix some format issue
Factor_List <- c("GG4_Toilets_Pay_Amount", "CC11_Population_Estimate", "CC10_Household_Size",
                 "CC12_Total_Population")
mydata[, (Factor_List) := lapply(.SD, as.numeric), .SDcols = Factor_List]

# remove useless factor
mydata[, c("Obs. Count", "City", "Country",
                       names(mydata)[grepl("Structure", names(mydata))],
                       names(mydata)[grepl("Ownership", names(mydata))]):=NULL]
# remove what are highly correlated to dependent variable
# write.csv(mydata, file = "D:/mydata_slum.csv")

# divide training and test dataset
set.seed(123)
train_idx <- sample(dim(mydata)[1], dim(mydata)[1]* 0.6)

# The model.matrix() function is used in many regression packages for building 
# an "X" matrix from data.
# need matrix for glmnet
X2 <- model.matrix(Share_Temporary~., data = mydata)
Y2 <- as.matrix(mydata[,"Share_Temporary"])
X_train <- X2[train_idx,]
X_test <- X2[-train_idx,]
Y_train <- Y2[train_idx]
Y_test <- Y2[-train_idx]
# merge back to df again, as df is required for regsubsets (best subset)
data_train <- data.frame(X2, Y2)[train_idx,] 
data_test <- data.frame(X2, Y2)[-train_idx,] 
```

# Summary plot  
* Using `geom_sina` from `ggforce` to make the sina plot  
* We can see clearly for the most influential variable on the top: Monthly water cost. A Higher cost is associated with the declined share of temporary housing. But a very low cost has a strong impact on the increased share of temporary housing  
* The effects of binary variables are highly distinctive. The second variable shows that Resettled housing is highly unlikely to be temporary, so does being close to wells as water sources.  
   
__Load the xgboost model__  
```{r, echo = T}
best_rmse_index <- 56
best_rmse <- 0.2102
best_seednumber <- 3660
best_param <- list(objective = "reg:linear",  # For regression
                eval_metric = "rmse",      # rmse is used for regression
                max_depth = 9,
                eta = 0.09822,   # Learning rate, default: 0.3
                subsample = 0.64,
                colsample_bytree = 0.6853, 
                min_child_weight = 6, # These two are important
                max_delta_step = 8)
# The best index (min_rmse_index) is the best "nround" in the model
nround <- best_rmse_index
set.seed(best_seednumber)
xg_mod <- xgboost(data = X_train, label = Y_train, params = best_param, nround = nround, verbose = F)

```
  
### Function to get SHAP value matrix  
__Also need it for the stacked plot for observation__  
```{r, echo = T}
## not necessary to use these functions... I just wrapped them up...
## return matrix of shap score and mean ranked score list
shap.score.rank <- function(xgb_model = xgb_mod, shap_approx = TRUE, 
                            X_train){
  require(xgboost)
  # `shap_contrib` returns the matrix of SHAP values: dim is (Number of obs)x(Number of Features)
  shap_contrib <- predict(xgb_model, X_train,
                          predcontrib = TRUE, approxcontrib = shap_approx)
  shap_contrib <- as.data.table(shap_contrib)
  shap_contrib[,BIAS:=NULL]
  # rank SHAP score by decreasing order:
  mean_shap_score <- colMeans(abs(shap_contrib))[order(colMeans(abs(shap_contrib)), decreasing = T)]
  return(list(shap_score = shap_contrib,
              mean_shap_score = (mean_shap_score)))
}

```
  
### Functions for summary plot  
__To get it work, please install 'ggforce' from github, as there was a bug in the new `geom_sina`__  
Now in `geom_sina` the default method is "density", to do it my originally way, need to change into `method = "counts", maxwidth = 0.7`  
  
```{r, eval = F}

devtools::install_github("thomasp85/ggforce")

```
  
```{r}
packageVersion("ggforce")

## a function to standardize feature values into same range
std1 <- function(x){
  return ((x - min(x, na.rm = T))/(max(x, na.rm = T) - min(x, na.rm = T)))
}

## prep shap data into long format, option to plot only `top_n` features  
shap.prep <- function(shap  = shap_result, X_train, top_n){
  # descending order
  if (missing(top_n)) top_n <- dim(X_train)[2] # by default, use all features
  if (!top_n%in%c(1:dim(X_train)[2])) stop('supply correct top_n')
  require(data.table)
  shap_score_sub <- as.data.table(shap$shap_score)
  shap_score_sub <- shap_score_sub[, names(shap$mean_shap_score)[1:top_n], with = F]
  shap_score_long <- melt.data.table(shap_score_sub, measure.vars = colnames(shap_score_sub))
  
  # feature values: the values in the original dataset
  fv_sub <- as.data.table(X_train)[, names(shap$mean_shap_score)[1:top_n], with = F]
  # standardize feature values
  fv_sub_long <- melt.data.table(fv_sub, measure.vars = colnames(fv_sub))
  fv_sub_long[, stdfvalue := std1(value), by = "variable"]
  # SHAP value: value
  # raw feature value: rfvalue; 
  # standarized: stdfvalue
  names(fv_sub_long) <- c("variable", "rfvalue", "stdfvalue" )
  shap_long2 <- cbind(shap_score_long, fv_sub_long[,c('rfvalue','stdfvalue')])
  shap_long2[, mean_value := mean(abs(value)), by = variable]
  setkey(shap_long2, variable)
  return(shap_long2) 
}

## the function to plot the summary plot:
plot.shap.summary <- function(data_long){
  x_bound <- max(abs(data_long$value))
  require('ggplot2')
  require('ggforce') # for `geom_sina`
  plot1 <- ggplot(data = data_long)+
    coord_flip() + 
    # sina plot: 
    geom_sina(aes(x = variable, y = value, color = stdfvalue),
              method = "counts", maxwidth = 0.7) +
    # print the mean absolute value on the left: 
    geom_text(data = unique(data_long[, c("variable", "mean_value"), with = F]),
              aes(x = variable, y=-Inf, label = sprintf("%.3f", mean_value)),
              size = 3, alpha = 0.7,
              hjust = -0.2, 
              fontface = "bold") + # bold
    # # if want to add a "SHAP" bar notation
    # annotate("text", x = -Inf, y = -Inf, vjust = -0.2, hjust = 0, size = 3,
    #          label = expression(group("|", bar(SHAP), "|"))) + 
    scale_color_gradient(low="#FFCC33", high="#6600CC", 
                         breaks=c(0,1), labels=c("Low","High")) +
    scale_y_continuous(limits = c(-x_bound, x_bound)) +
    # reverse the order of features
    scale_x_discrete(limits = rev(levels(data_long$variable))) + 
    geom_hline(yintercept = 0) + # the vertical line
    labs(y = "SHAP value (impact on model output)", x = "", color = "Feature value") +
    theme_bw() + 
    theme(axis.line.y = element_blank(), axis.ticks.y = element_blank(), # remove axis line
          legend.position="bottom")
  return(plot1)
}

## Prepare data:
shap_result <- shap.score.rank(xgb_model = xg_mod, shap_approx = F, 
                               X_train = X_train)
shap_long <- shap.prep(X_train = X_train, top_n = 10)
## The data prepared: variable, SHAP value, raw feature value, standarded feature value, mean value by feature
print(shap_long)
## make summary plot
plot.shap.summary(data_long = shap_long)

```
  
# SHAP plot for each feature  
* Using the built-in `xgb.plot.shap` function
* Here we choose to show top 9 features ranked by impact on the dependent variable  
```{r, echo = T}
f_ranked <- names(shap_result$mean_shap_score)
xgb.plot.shap(data = X_train, model = xg_mod, features = f_ranked[1:6], n_col = 3)
```
  
# SHAP stack plot for observation  
* Using `geom_col` to "show features each contributing to push the model output from the base value (the average model output) to the model output."  
* Tried `geom_area` but dones't work very well due to gaps in the plot caused by fluctuation of positive and negative values
     
### Function for stack plot   
```{r}
# uses the shap_result from `shap.score.rank`, mainly contains the SHAP value matrix 
shap.stack.plot <- function(shap_result, top_n, data_percent = 1){
  require('data.table')
  require('ggplot2')
  require('ggforce') # for zoom in (the way to write it has been updated in the new version)
  ranked_col <- names(shap_result$mean_shap_score)
  top_ranked_col <- ranked_col[1:top_n]
  bottom_col <- ranked_col[-(1:top_n)]
  shap_contrib2 <- setDT(shap_result$shap_score)[,..ranked_col]
  # plot part of the data if needed
  set.seed(1234)
  shap_contrib2 <- shap_contrib2[sample(.N, .N * data_percent)]
  shap_contrib2[, yhat:= rowSums(.SD)]
  shap_contrib2[, rest_variables:= rowSums(.SD), .SDcol = bottom_col]
  
  # shap_contrib2 <- shap_contrib2[1:100]
  setkey(shap_contrib2, yhat)
  shap_contrib2[,id:= .I]
  
  # dataset with desired variables for plot
  shapobs <- shap_contrib2[, c("id", top_ranked_col, "rest_variables"), with = F]
  shapobs_long <- melt.data.table(shapobs, id.vars = 'id')
  
  ## make the stack plot
  x_mid <- shap_contrib2[,median(id)*1.4] # optional: location to zoom in certain part of the plot
  p <- ggplot(shapobs_long, aes(x = id, y = value , fill = variable)) + 
    geom_col(width = 1, alpha = 0.9) +
    scale_fill_viridis_d(option = "D") + # viridis color scale
    # theme(axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
    labs(fill = 'Feature', x = 'Observation', 
         y = 'SHAP values by feature:\n (Contribution to the base value)') + 
    # zoom in if needed, it requires the ggforce 0.2.1 (the new version)
    ggforce::facet_zoom(xlim = c(x_mid, x_mid+max(20, shap_contrib2[,.N]*0.01))) +
    theme(zoom.y = element_blank(), validate = FALSE) +
    theme_bw() 
  p
  return(p)
}

# use the SHAP value matrix created above and stored in object `shap_result`  
## Prepare data:
shap_result <- shap.score.rank(xgb_model = xg_mod, shap_approx = F, 
                               X_train = X_train)
shap.stack.plot(shap_result = shap_result, top_n = 6, data_percent = 1)

```

  
  