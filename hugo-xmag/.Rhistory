col.names = F, append = F, sep = ",")
attachResult <- function(x){
print(x)
write.table(getOutput(x),
"C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy output.csv",
col.names = F, append = T, sep = ",")
}
Blank <- lapply(dir_list[-c(1,2)], attachResult)
?write.table
df <- getOutput(dir_list[2])
write.table(df, "C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy output.csv",
row.names = F, append = F, sep = ",")
## find empty directory
dir_list [sapply(dir_list, function(x) length(list.files(x))==0)]
city_list <- list.files(parent_dir)
df <- getOutput(dir_list[2])
write.table(df, "C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy output.csv",
row.names = F, append = F, sep = ",")
attachResult <- function(x){
# print(x)
write.table(getOutput(x),
"C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy output.csv",
row.names = F, append = T, sep = ",")
}
Blank <- lapply(dir_list[-c(1,2)], attachResult)
city_list <- list.files(parent_dir)
df <- getOutput(dir_list[2])
write.table(df, "C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy output.csv",
row.names = F, append = F, sep = ",")
attachResult <- function(x){
# print(x)
write.table(getOutput(x),
"C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy output.csv",
row.names = F, col.names = F, append = T, sep = ",")
}
Blank <- lapply(dir_list[-c(1,2)], attachResult)
Acc <- read.csv("C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy output.csv")
# Abs_Diff vs. GT_Builtup
qplot(data = Acc, x = Acc$GT_Builtup_mean, y = Acc$NYUvsGT_AbsMeanDiff)
##
library("lubridate")
qplot(x = Acc$NYUvsGT_AbsMeanDiff, y = Acc$NYU1vsGT_Accuracy, label = Acc$City)+
geom_smooth(method = 'lm')
Acc$City <- as.character(Acc$City)
Acc$City_Lable <- ifelse((Acc$GHSvsGT_AbsMeanDiff > 0.3)|
(Acc$Img_date_sd > 600), Acc$City, "")
Acc$Time_Diff <- (mdy(Acc$Img_date_mean) - mdy(Acc$GHSL_date))
Diff_Acc <- Acc$NYU1vsGT_Accuracy - Acc$GHS1vsGT_Accuracy
Acc$City_short[duplicated(Acc$City_short)]
# Doesn't matter weighted by N_locals or not
t.test(x = Acc$NYU2vsGT_Accuracy, y = Acc$GHS2vsGT_Accuracy) # NS
# Doesn't matter weighted by N_locals or not
t.test(x = Acc$NYU2vsGT_Accuracy, y = Acc$GHS2vsGT_Accuracy) # NS
# vs. Climate region ------------------------------------------------------
source("D:/NYU Marron/R/Get Weighted SE and CI.R")
Acc_Climate <- get_WM_and_CI2(Acc2, "Climate_Group", "NYU1vsGT_Accuracy", "weight")
rm(list=ls())
library('foreign')
library('equivalence')
library('lubridate')
# functions  ----------------------------------------------------------
## get mode
Get_Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# Sensitivity: producers accuracy built up
# Get sensitivity: 11/ (11 + 01)
get_Sen <- function(var){
sum(var=='11')/(sum(var=='11') + sum(var=='01'))
}
# Specificty: producers accuracy open space
# Get specifity: 00 / (00 + 10)
get_Spe <- function(var){
sum(var=='00')/(sum(var=='00') + sum(var=='10'))
}
# PPV Positive predictive value: users accuracy bulit up
# Get PPV: 11 / (11 + 01)
get_PPV <- function(var){
sum(var=='11')/(sum(var=='11') + sum(var=='10'))
}
# NPV Negative predictive value: users accuracy open space
# Get NPV: 00 / (00 + 01)
get_NPV <- function(var){
sum(var=='00')/(sum(var=='00') + sum(var=='01'))
}
# Overall accuracy = (11 + 00) / (11 + 00 + 10 + 01)
get_Accu <- function(var){
(sum(var=='00') + sum(var=='11'))/length(var)
}
# Get percent of Builtup tiles in each locale (ID_string)
get_Builtup <- function(var) {sum(var)/length(var)}
## Combine functions above, get confusion matrix
group_Analysis <- function(Var_GT){
Var <- substr(substitute(Var_GT),1,4)
GT_Sen <- get_Sen(Var_GT)
GT_Spe <- get_Spe(Var_GT)
GT_PPV <- get_PPV(Var_GT)
GT_NPV <- get_NPV(Var_GT)
GT_Acc <- get_Accu(Var_GT)
out <- data.frame(GT_Sen, GT_Spe, GT_PPV, GT_NPV, GT_Acc)
names(out) <- c(paste(Var,"vsGT_Sensitivity", sep = ""), paste(Var,"vsGT_Specificty", sep = ""),
paste(Var,"vsGT_PPV", sep = ""), paste(Var,"vsGT_NPV", sep = ""),
paste(Var,"vsGT_Accuracy", sep = ""))
return(out)
}
#>Merge all the locales ------------------------------------------------------
getAllLocales <- function(file){
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
# clean the variable names
names(city) <- gsub("_", "", x = names(city))
require('lubridate')
city$Imgdate <- ymd(city$Imgdate)
G1 <- aggregate(x = city$IDstring, by = list(city$IDstring),
FUN = length)
names(G1) <- c("IDstring","Num_Pixel")
## name of the group & the city
G1$City <- levels(city$City)[1]
G1$IDstring <- paste("_", G1$IDstring, sep = "")
## dates
G1$GT_Date <- aggregate(x = city$Imgdate, by = list(city$IDstring), FUN = mean)$x
# average Builtup in all locales of a city
G1$NYU_Builtup <- aggregate(x = city$NYUName, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GHS_Builtup <- aggregate(x = city$GHSLName, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GT_Builtup <- aggregate(x = city$GTName, by = list(city$IDstring),
FUN = get_Builtup)$x
## Binary builtup, turns builtup in each locale into binary judgement
G1$Binary_GT <- G1$Binary_GHS <- G1$Binary_NYU <- rep(0, length(G1$GT_Builtup))
G1$Binary_NYU[G1$NYU_Builtup>=0.5] <- 1
G1$Binary_GHS[G1$GHS_Builtup>=0.5] <- 1
G1$Binary_GT[G1$GT_Builtup>=0.5] <- 1
## is there any big locale with pixel > 400?
G1$Big_Locale <- 0
G1$Big_Locale[G1$Num_Pixel > 400] <- 1
G1 <- G1[G1$Big_Locale == 0, ]  # remove big locales
G1 <- subset(G1, select = -Big_Locale) # remove this column
return(G1)
}
# for chicago
G_test <- getAllLocales(File_List[37])
getAllLocales <- function(file){
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
# clean the variable names
names(city) <- gsub("_", "", x = names(city))
require('lubridate')
city$Imgdate <- ymd(city$Imgdate)
G1 <- aggregate(x = city$IDstring, by = list(city$IDstring),
FUN = length)
names(G1) <- c("IDstring","Num_Pixel")
## name of the group & the city
G1$City <- levels(city$City)[1]
G1$IDstring <- paste("_", G1$IDstring, sep = "")
## dates
G1$GT_Date <- aggregate(x = city$Imgdate, by = list(city$IDstring), FUN = mean)$x
# average Builtup in all locales of a city
G1$NYU_Builtup <- aggregate(x = city$NYUName, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GHS_Builtup <- aggregate(x = city$GHSLName, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GT_Builtup <- aggregate(x = city$GTName, by = list(city$IDstring),
FUN = get_Builtup)$x
## Binary builtup, turns builtup in each locale into binary judgement
G1$Binary_GT <- G1$Binary_GHS <- G1$Binary_NYU <- rep(0, length(G1$GT_Builtup))
G1$Binary_NYU[G1$NYU_Builtup>=0.5] <- 1
G1$Binary_GHS[G1$GHS_Builtup>=0.5] <- 1
G1$Binary_GT[G1$GT_Builtup>=0.5] <- 1
## is there any big locale with pixel > 400?
G1$Big_Locale <- 0
G1$Big_Locale[G1$Num_Pixel > 400] <- 1
G1 <- G1[G1$Big_Locale == 0, ]  # remove big locales
G1 <- subset(G1, select = -Big_Locale) # remove this column
return(G1)
}
dir_list <- list.dirs(parent_dir)[-1]
# for chicago
parent_dir <- "C:/Users/Roxy/OneDrive - nyu.edu/Accuracy/"
dir_list <- list.dirs(parent_dir)[-1]
head(dir_list)
G_test <- getAllLocales(dir_list[37])
getAllLocales <- function(dir){
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
# clean the variable names
names(city) <- gsub("_", "", x = names(city))
require('lubridate')
city$Imgdate <- ymd(city$Imgdate)
G1 <- aggregate(x = city$IDstring, by = list(city$IDstring),
FUN = length)
names(G1) <- c("IDstring","Num_Pixel")
## name of the group & the city
G1$City <- levels(city$City)[1]
G1$IDstring <- paste("_", G1$IDstring, sep = "")
## dates
G1$GT_Date <- aggregate(x = city$Imgdate, by = list(city$IDstring), FUN = mean)$x
# average Builtup in all locales of a city
G1$NYU_Builtup <- aggregate(x = city$NYUName, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GHS_Builtup <- aggregate(x = city$GHSLName, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GT_Builtup <- aggregate(x = city$GTName, by = list(city$IDstring),
FUN = get_Builtup)$x
## Binary builtup, turns builtup in each locale into binary judgement
G1$Binary_GT <- G1$Binary_GHS <- G1$Binary_NYU <- rep(0, length(G1$GT_Builtup))
G1$Binary_NYU[G1$NYU_Builtup>=0.5] <- 1
G1$Binary_GHS[G1$GHS_Builtup>=0.5] <- 1
G1$Binary_GT[G1$GT_Builtup>=0.5] <- 1
## is there any big locale with pixel > 400?
G1$Big_Locale <- 0
G1$Big_Locale[G1$Num_Pixel > 400] <- 1
G1 <- G1[G1$Big_Locale == 0, ]  # remove big locales
G1 <- subset(G1, select = -Big_Locale) # remove this column
return(G1)
}
# for chicago
parent_dir <- "C:/Users/Roxy/OneDrive - nyu.edu/Accuracy/"
dir_list <- list.dirs(parent_dir)[-1]
G_test <- getAllLocales(dir_list[37])
dir = dir_list[1]
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
# clean the variable names
names(city) <- gsub("_", "", x = names(city))
require('lubridate')
city$Imgdate <- ymd(city$Imgdate)
G1 <- aggregate(x = city$IDstring, by = list(city$IDstring),
FUN = length)
names(G1) <- c("IDstring","Num_Pixel")
## name of the group & the city
G1$City <- levels(city$City)[1]
G1$IDstring <- paste("_", G1$IDstring, sep = "")
## dates
G1$GT_Date <- aggregate(x = city$Imgdate, by = list(city$IDstring), FUN = mean)$x
# average Builtup in all locales of a city
G1$NYU_Builtup <- aggregate(x = city$NYUName, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GHS_Builtup <- aggregate(x = city$GHSLName, by = list(city$IDstring),
FUN = get_Builtup)$x
rm(list=ls())
library('foreign')
library('equivalence')
library('lubridate')
# functions  ----------------------------------------------------------
## get mode
Get_Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# Sensitivity: producers accuracy built up
# Get sensitivity: 11/ (11 + 01)
get_Sen <- function(var){
sum(var=='11')/(sum(var=='11') + sum(var=='01'))
}
# Specificty: producers accuracy open space
# Get specifity: 00 / (00 + 10)
get_Spe <- function(var){
sum(var=='00')/(sum(var=='00') + sum(var=='10'))
}
# PPV Positive predictive value: users accuracy bulit up
# Get PPV: 11 / (11 + 01)
get_PPV <- function(var){
sum(var=='11')/(sum(var=='11') + sum(var=='10'))
}
# NPV Negative predictive value: users accuracy open space
# Get NPV: 00 / (00 + 01)
get_NPV <- function(var){
sum(var=='00')/(sum(var=='00') + sum(var=='01'))
}
# Overall accuracy = (11 + 00) / (11 + 00 + 10 + 01)
get_Accu <- function(var){
(sum(var=='00') + sum(var=='11'))/length(var)
}
# Get percent of Builtup tiles in each locale (ID_string)
get_Builtup <- function(var) {sum(var)/length(var)}
## Combine functions above, get confusion matrix
group_Analysis <- function(Var_GT){
Var <- substr(substitute(Var_GT),1,4)
GT_Sen <- get_Sen(Var_GT)
GT_Spe <- get_Spe(Var_GT)
GT_PPV <- get_PPV(Var_GT)
GT_NPV <- get_NPV(Var_GT)
GT_Acc <- get_Accu(Var_GT)
out <- data.frame(GT_Sen, GT_Spe, GT_PPV, GT_NPV, GT_Acc)
names(out) <- c(paste(Var,"vsGT_Sensitivity", sep = ""), paste(Var,"vsGT_Specificty", sep = ""),
paste(Var,"vsGT_PPV", sep = ""), paste(Var,"vsGT_NPV", sep = ""),
paste(Var,"vsGT_Accuracy", sep = ""))
return(out)
}
#>Merge all the locales ------------------------------------------------------
getAllLocales <- function(dir){
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
# clean the variable names
names(city) <- gsub("_", "", x = names(city))
require('lubridate')
city$Imgdate <- ymd(city$Imgdate)
G1 <- aggregate(x = city$IDstring, by = list(city$IDstring),
FUN = length)
names(G1) <- c("IDstring","Num_Pixel")
## name of the group & the city
G1$City <- levels(city$City)[1]
G1$IDstring <- paste("_", G1$IDstring, sep = "")
## dates
G1$GT_Date <- aggregate(x = city$Imgdate, by = list(city$IDstring), FUN = mean)$x
# average Builtup in all locales of a city
G1$NYU_Builtup <- aggregate(x = city$NYU, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GHS_Builtup <- aggregate(x = city$GHSL, by = list(city$IDstring),
FUN = get_Builtup)$x
G1$GT_Builtup <- aggregate(x = city$GT, by = list(city$IDstring),
FUN = get_Builtup)$x
## Binary builtup, turns builtup in each locale into binary judgement
G1$Binary_GT <- G1$Binary_GHS <- G1$Binary_NYU <- rep(0, length(G1$GT_Builtup))
G1$Binary_NYU[G1$NYU_Builtup>=0.5] <- 1
G1$Binary_GHS[G1$GHS_Builtup>=0.5] <- 1
G1$Binary_GT[G1$GT_Builtup>=0.5] <- 1
## is there any big locale with pixel > 400?
G1$Big_Locale <- 0
G1$Big_Locale[G1$Num_Pixel > 400] <- 1
G1 <- G1[G1$Big_Locale == 0, ]  # remove big locales
G1 <- subset(G1, select = -Big_Locale) # remove this column
return(G1)
}
# for chicago
parent_dir <- "C:/Users/Roxy/OneDrive - nyu.edu/Accuracy/"
dir_list <- list.dirs(parent_dir)[-1]
G_test <- getAllLocales(dir_list[37])
head(G_test)
#>Merge all the locales ------------------------------------------------------
parent_dir <- "C:/Users/Roxy/OneDrive - nyu.edu/Accuracy/"
dir_list <- list.dirs(parent_dir)[-1]
G_test <- getAllLocales(dir_list[37])
head(G_test)
df <- getAllLocales(dir_list[1])
write.table(df, "C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0607_Accuracy All Locales.csv",
col.names = T, row.names = F, append = F, sep = ",")
attachResult <- function(x){
# print(x)
write.table(getAllLocales(x),"C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0607_Accuracy All Locales.csv",
col.names = F, row.names = F, append = T, sep = ",")
}
Blank <- lapply(dir_list[-1],attachResult)
#>Analysis of the <all-locale> output ------------------------------------------------
##
AccLocales <- read.csv("C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0607_Accuracy All Locales.csv")
head(AccLocales)
Binary_NYU_GT  <- paste(AccLocales$Binary_NYU, AccLocales$Binary_GT, sep="")
Binary_GHS_GT  <- paste(AccLocales$Binary_GHS, AccLocales$Binary_GT, sep="")
Binary_NYU_GHS <- paste(AccLocales$Binary_NYU, AccLocales$Binary_GHS, sep="")
group_Analysis_2 <- function(Var_GT){
GT_Sen <- get_Sen(Var_GT)
GT_Spe <- get_Spe(Var_GT)
GT_PPV <- get_PPV(Var_GT)
GT_NPV <- get_NPV(Var_GT)
GT_Acc <- get_Accu(Var_GT)
out <- data.frame(GT_Sen, GT_Spe, GT_PPV, GT_NPV, GT_Acc)
return(out)
}
lapply(list(NYUvsGT = Binary_NYU_GT,
GHSvsGT = Binary_GHS_GT,
NYUvsGHS = Binary_NYU_GHS), group_Analysis_2)
## Abs_Diff vs. Builtup
AccLocales$Days_Diff <- ymd(AccLocales$GHS_Date) - ymd(AccLocales$GT_Date)
Builtup_Breaks <- seq(0, 1, by = 0.1)
AccLocales$Builtup_Group <- cut(AccLocales$GT_Builtup, breaks = Builtup_Breaks)
AccLocales <- AccLocales[!is.na(AccLocales$Builtup_Group),]
# boxplot by artificial groups of GT builtup
ggplot(data = AccLocales, aes(x = Builtup_Group, y = Abs_Diff))+
geom_boxplot() +
theme_classic()
# boxplot by artificial groups of GT builtup
ggplot(data = AccLocales, aes(x = Builtup_Group, y = Abs_Diff))+
geom_boxplot() +
theme_classic()
#
AccLocales$weight_blank <- 1
source("C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/R/Get Weighted SE and CI.R")
Mean_byGroup <- get_WM_and_CI2(AccLocales, "Builtup_Group", "Abs_Diff", "weight_blank")
#
# >Merge all the pixels ----------------------------------------------------
getAllPixels <- function(dir){
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
city$IDstring <- paste("_", city$IDstring, sep = "")
if (length(city$Skipped) == 0) city$Skipped = NA
df <- city[c("City","IDstring","Imgdate","NYUDate","GHSLDate","Skipped",
"GT", "NYU", "GHSL")]
return(df)
}
P_test  <-  getAllPixels(dir_list[37])
head(P_test)
city
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
dir = dir_list[1]
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
city$IDstring <- paste("_", city$IDstring, sep = "")
names(city)
#
# >Merge all the pixels ----------------------------------------------------
getAllPixels <- function(dir){
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
city$IDstring <- paste("_", city$IDstring, sep = "")
if (length(city$Skipped) == 0) city$Skipped = NA
df <- city[c("City","IDstring","Imgdate","Skipped",
"GT", "NYU", "GHSL")]
return(df)
}
P_test  <-  getAllPixels(dir_list[37])
city <- read.dbf(File_Directory)
city$IDstring <- paste("_", city$IDstring, sep = "")
if (length(city$Skipped) == 0) city$Skipped = NA
df <- city[c("City","IDstring","Imgdate","Skipped",
"GT", "NYU", "GHSL")]
head(city)
names(city) <- gsub("_", "", x = names(city))
city <- read.dbf(File_Directory)
names(city) <- gsub("_", "", x = names(city))
city$IDstring <- paste("_", city$IDstring, sep = "")
if (length(city$Skipped) == 0) city$Skipped = NA
df <- city[c("City","IDstring","Imgdate","Skipped",
"GT", "NYU", "GHSL")]
df
head(df)
#
# >Merge all the pixels ----------------------------------------------------
getAllPixels <- function(dir){
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
names(city) <- gsub("_", "", x = names(city))
city$IDstring <- paste("_", city$IDstring, sep = "")
if (length(city$Skipped) == 0) city$Skipped = NA
df <- city[c("City","IDstring","Imgdate","Skipped",
"GT", "NYU", "GHSL")]
return(df)
}
P_test  <-  getAllPixels(dir_list[37])
head(P_test)
df <- getAllPixels(dir_list[1])
df <- getAllLocales(dir_list[1])
write.table(df, "C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy All Locales.csv",
col.names = T, row.names = F, append = F, sep = ",")
attachResult <- function(x){
# print(x)
write.table(getAllLocales(x),"C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy All Locales.csv",
col.names = F, row.names = F, append = T, sep = ",")
}
Blank <- lapply(dir_list[-1],attachResult)
#
# >Merge all the pixels ----------------------------------------------------
getAllPixels <- function(dir){
File_Directory <- paste(dir, "/Compare_point_identity.dbf", sep = "")
city <- read.dbf(File_Directory)
names(city) <- gsub("_", "", x = names(city))
city$IDstring <- paste("_", city$IDstring, sep = "")
if (length(city$Skipped) == 0) city$Skipped = NA
df <- city[c("City","IDstring","Imgdate","Skipped",
"GT", "NYU", "GHSL")]
return(df)
}
P_test  <-  getAllPixels(dir_list[37])
head(P_test)
df <- getAllPixels(dir_list[1])
write.table(df, "C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy All Pixels.csv",
col.names = T, row.names = F, append = F, sep = ",")
attachResult <- function(x){
# print(x)
write.table(getAllPixels(x),"C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy All Pixels.csv",
col.names = F, row.names = F, append = T, sep = ",")
}
dir_list[1]
attachResult <- function(x){
# print(x)
write.table(getAllPixels(x),"C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy All Pixels.csv",
col.names = F, row.names = F, append = T, sep = ",")
}
Blank <- lapply(dir_list[c(2:length(dir_list))],attachResult)
# >Analysis all pixels ----------------------------------------------------
library(data.table)
Pixels <- fread("C:/Users/Roxy/OneDrive - nyu.edu/NYU Marron/Data3_R/0721_Accuracy All Pixels.csv")
NYU_GT <- paste(Pixels$NYU, Pixels$GT, sep="")
GHS_GT <- paste(Pixels$GHSL, Pixels$GT, sep="")
NYU_GHS <- paste(Pixels$NYU, Pixels$GHSL, sep="")
lapply(list(NYU_GT, GHS_GT, NYU_GHS), group_Analysis_2)
get_table <- function(a,b){
df <- data.frame(a,b)
df2 <- na.omit(df)
table(df2$a, df2$b)
}
get_table(Pixels$NYU, Pixels$GHSL)
# Overall accuracy = (11 + 00) / (11 + 00 + 10 + 01)
get_Kappa <- function(var){
a = sum(var == '11')
b = sum(var == "10")
c = sum(var == "01")
d = sum(var == "00")
sum = a + b + c + d
p0 <- (a+d)/sum
pYes <- (a+b)*(a+c)/sum^2
pNo  <- (c+d)*(b+d)/sum^2
pe <- pYes+pNo
(p0-pe)/(1-pe)
}
lapply(list(NYU_GT, GHS_GT,NYU_GHS), get_Sen)
sapply(list(NYU_GT, GHS_GT,NYU_GHS), get_Sen)
setwd("D:/OneDrive/R_Blog_Github/Blogdown/hugo-xmag")
blogdown:::serve_site()
blogdown:::serve_site()
