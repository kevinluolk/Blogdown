X2 <- model.matrix(Share_Temporary~., data = mydata)
Y2 <- as.matrix(mydata[,"Share_Temporary"])
X_train <- X2[train_idx,]
X_test <- X2[-train_idx,]
Y_train <- Y2[train_idx]
Y_test <- Y2[-train_idx]
# merge back to df again, as df is required for regsubsets (best subset)
data_train <- data.frame(X2, Y2)[train_idx,]
mydata2 <- data.frame(X2, Y2)
## Working Sample: Predicting Share of Temporary Structure in Slums Settlements ##
## use data table
# 07/09/2018
library(data.table)
library(plyr)
library(ggplot2)
library(QuantPsyc)     # used to show standardized regression coefficients
library(glmnet)        # for Lasso
library(leaps)         # for best subset
library(randomForest)  # random forest
library(gbm)           # for Gradient boosting
library(caret)         # grid scan by train
library(xgboost)       # for Extreme Gradient boosting
library(Ckmeans.1d.dp) # for xgb.ggplot.importance in xgboost
library(DiagrammeR)    # for xgb.plot.tree in xgboost
library(knitr)
options(digits = 4)
# Data Preparation -----------------------------------------------------------
mydata <- fread("D:/OneDrive - nyu.edu/NYU Marron/Data/20180618_sdi 2.csv", stringsAsFactors = TRUE)
# clean variables names, remove "/".
names(mydata) <- gsub("/", "", names(mydata))
# create variable: Share_Temporary
# The dependent variable to be modeled: Share of temporary structure in slums
mydata[, Share_Temporary := CC7_Structures_Temporary / (CC7_Structures_Temporary + CC6_Structures_Permanent)]
# remove variables with over 20% NA, var_keeps those is.na < 20%
var_keep <- sapply(mydata, function(x) sum(is.na(x))) < dim(mydata)[1]*0.2
var_keep[length(var_keep)] <- TRUE # keep "Share_Temporary"
mydata[, names(mydata)[!var_keep]:= NULL]
mydata <- na.omit(mydata) # remove rest N.A.
# fix some format issue
Factor_List <- c("GG4_Toilets_Pay_Amount", "CC11_Population_Estimate", "CC10_Household_Size",
"CC12_Total_Population")
mydata[, (Factor_List) := lapply(.SD, as.numeric), .SDcols = Factor_List]
# remove useless factor
mydata[, c("Obs. Count", "City", "Country",
names(mydata)[grepl("Structure", names(mydata))],
names(mydata)[grepl("Ownership", names(mydata))]):=NULL]
# remove what are highly correlated to dependent variable
###
# divide training and test dataset
set.seed(123)
train_idx <- sample(dim(mydata)[1], dim(mydata)[1]* 0.6)
# The model.matrix() function is used in many regression packages for building
# an "X" matrix from data.
# need matrix for glmnet
X2 <- model.matrix(Share_Temporary~., data = mydata)
Y2 <- as.matrix(mydata[,"Share_Temporary"])
X_train <- X2[train_idx,]
X_test <- X2[-train_idx,]
Y_train <- Y2[train_idx]
Y_test <- Y2[-train_idx]
# merge back to df again, as df is required for regsubsets (best subset)
data_train <- data.frame(X2, Y2)[train_idx,]
mydata2 <- data.frame(X2, Y2)
# write.csv(mydata2, "D:/NYU Marron/Data3_R/mydata2.csv")
# data ready -------------------------------------------
# 1. Lasso ----------------------------------------------------------------
# Use cross-validation to choose lambda for Lasso
cv_lasso = cv.glmnet(X_train, Y_train, alpha=1) # Lasso regression
plot.cv.glmnet(cv_lasso)
(best_lam <- cv_lasso$lambda.1se)
coef_table <- coef(cv_lasso, s = cv_lasso$lambda.1se)
# variables chosen
# data.frame(name = coef_table@Dimnames[[1]][coef_table@i + 1], coefficient = coef_table@x)
# Check prediction error in test dataset
# The lasso model, then feed lambda to predict fitted value
lasso_mod <- glmnet(X_train, Y_train, alpha = 1)
# As lambda increase, "survived" variables decrease as coefficients move to zero
plot(lasso_mod, xvar = "lambda", label = TRUE)
lasso_pred <- predict(lasso_mod, s = best_lam, newx = X_test)
# The MSE (Mean square error)
(MSE_Lasso <- mean((lasso_pred - Y_test)^2))
# show the variables chosen into the model
var_list <- unlist(coef_table@Dimnames[[1]][coef_table@i + 1])
var_list
# run a regression using these variables
# Because there is intercept, we need to use [coef_table@i + 1], and [-1] in the end
mydata_sub <- mydata2[c(coef_table@Dimnames[[1]][coef_table@i + 1], "Share_Temporary")[-1]]
# lm model using variables chosen by Lasso 1se
reg.chosen1 <- lm(data = mydata_sub, Share_Temporary~.)
summary(reg.chosen1)
# Relative importance by showing Standardized parameter estimates in decreasing order
coef_table <- data.frame(b = reg.chosen1$coefficients, stb = c(0, lm.beta(reg.chosen1)))
coef_table[order(abs(coef_table$stb), decreasing = T),]
# 2. Best Subset ----------------------------------------------------------
#
# time_now <- Sys.time()
# nv_max <- 5 # the maximum allowed number of features to test
# fit_s <- regsubsets(Share_Temporary~., data_train,
#                     really.big = T, nbest=1, nvmax = nv_max
# )
# Sys.time() - time_now
#
# val.errors =rep(0, nv_max)
# # Need the X_test with intercept
# for(i in 1:nv_max){
#   coefi = coef(fit_s, id=i)
#   pred = X_test[,names(coefi)]%*%coefi # need to use matrix here
#   val.errors[i]= mean((Y_test - pred)^2)
# }
# # choose the best number of predictors to use
# (val_err_min <- which.min(val.errors))
# # MSE
# (MSE_best.subset <- val.errors[val_err_min])
#
# # The reg model selected:
# coef_list = coef(fit_s, id = val_err_min)
# # create mydata_sub2 which has all the selected predictors, and dependent variable,
# # remove intercept by adding [-1]
# mydata_sub2 <- mydata2[c(names(coef_list), "Share_Temporary")[-1]]
# reg_chosen_bs <- lm(data = mydata_sub2, Share_Temporary ~ .)
# summary(reg_chosen_bs)
#
# # get output of b and stb sorted by |stb|
# coef_table_bs <- data.frame(b = reg_chosen_bs$coefficients, stb = c(0, lm.beta(reg_chosen_bs)))
# coef_table_bs[order(abs(coef_table_bs$stb), decreasing = T),]
# the chosen model from cross-validation
reg.chosen4 <- lm(data = mydata2[train_idx, ], Share_Temporary~
FF11_Water_MonthlyCost +
B14__resettled	+
Eviction_Threats	+
DD1_Location_Problemsflood_prone_area	+
FF1_8_Water_Sourcesshared_taps	+
DD1_Location_Problemscanal	+
FF1_8_Water_Sourceswater_tankers	+
B14__declared_legal_protected	+
FF1_8_Water_Sourcessprings	+
JJ1_Electricity_Availableyes	+
GG7_10_Toilet_Typesindividual_toilets	+
FF1_8_Water_Sourcesdams	+
FF1_8_Water_Sourcesrivers	+
FF12_Water_CollectionTime30_minutes	+
DD1_Location_Problemsroad_side	+
DD1_Location_Problemsgarbage_dump +
JJ1_Electricity_Availableyes
)
# MSE
(MSE_best.subset <- mean((predict(reg.chosen4, mydata2[-train_idx,]) - Y_test)^2))
# 3. Random Forest --------------------------------------------------------
# Easy to use, there is no hyperparameter to tune
bag.fit <- randomForest(Share_Temporary ~ ., data = mydata2, subset = train_idx)
# rf_test <- mydata[-train_idx, "Share_Temporary"]
# test on test data: mydata[-train_idx,]
yhat_bag <- predict(bag.fit, newdata = mydata2[-train_idx,])
# MSE
(MSE_rForest <- mean((yhat_bag - Y_test)^2))
varImpPlot(bag.fit, n.var=15)
# 4. Gradiant boosting ----------------------------------------------------
# Tuning Method: use `train` function from `caret` to scan for parameters.
library(gbm)   # for Gradiant boosting
library(caret) # scan the parameter grid using `train` function
time_now <- Sys.time()
para_grid <- expand.grid(n.trees = (20*c(50:100)),
shrinkage = c(0.1, 0.05, 0.01),
interaction.depth = c(1,3,5),
n.minobsinnode = 10)
trainControl <- trainControl(method = "cv", number = 10)
set.seed(123)
gbm_caret <- train(Share_Temporary ~ ., mydata2[train_idx,],
distribution = "gaussian", method = "gbm",
trControl = trainControl, verbose = FALSE,
tuneGrid = para_grid, metric = "RMSE", bag.fraction = 0.75)
# The tuning parameters that give lowest MSE in training set CV.
gbm_caret$bestTune
yhat_boost <- predict(gbm_caret, mydata2[-train_idx,])
(MSE_boost <- mean((yhat_boost - Y_test)^2))
Sys.time() - time_now
# 5. Extreme Gradiant Boosting --------------------------------------------------------------
# Tuning Method: randomnize parameters and update the record with best ones.
library(xgboost)
# Matrix for xgb: dtrain
dtrain <- xgb.DMatrix(X_train, label = Y_train)
dtest <- xgb.DMatrix(X_test, label = Y_test)
# # For a single cv
# xg_cv <- xgb.cv(data = dtrain, nrounds = 3, nthread = 2, nfold = 5,
#              max_depth = 3, eta = 0.1, objective = "reg:linear",
#              eval_metric = "rmse")
# print(xg_cv)
# Randomize and bound
best_param <- list()
best_seednumber <- 1234
best_rmse <- Inf
best_rmse_index <- 0
time_now <- Sys.time()
set.seed(1234)
for (iter in 1:10) {
param <- list(objective = "reg:linear",  # For regression
eval_metric = "rmse",      # rmse is used for regression
max_depth = sample(6:10, 1),
eta = runif(1, .01, .1),   # Learning rate, default: 0.3
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:10, 1), # These two are important
max_delta_step = sample(5:10, 1)    # Can help to focus error into a
# small range.
)
cv.nround <-  1000
cv.nfold <-  5 # 5-fold cross-validation
seed.number  <-  sample.int(10000, 1) # set seed for the cv
set.seed(seed.number)
mdcv <- xgb.cv(data = dtrain, params = param,
nfold = cv.nfold, nrounds = cv.nround,
verbose = F, early_stopping_rounds = 8, maximize = FALSE)
min_rmse_index  <-  mdcv$best_iteration
min_rmse <-  mdcv$evaluation_log[min_rmse_index]$test_rmse_mean
if (min_rmse < best_rmse) {
best_rmse <- min_rmse
best_rmse_index <- min_rmse_index
best_seednumber <- seed.number
best_param <- param
}
}
# The best index (min_rmse_index) is the best "nround" in the model
nround = best_rmse_index
set.seed(best_seednumber)
xg_mod <- xgboost(data = dtest, params = best_param, nround = nround, verbose = F)
# Check error in testing data
yhat_xg <- predict(xg_mod, dtest)
(MSE_xgb <- mean((yhat_xg - Y_test)^2))
best_param_store <- data.frame(best_param, best_rmse_index, best_rmse, best_seednumber)
Sys.time() - time_now
# Feature importance
importance_matrix <- xgb.importance(colnames(X_train), model = xg_mod)
# Use `xgb.plot.importance`, which create a _barplot_ or use `xgb.ggplot.importance`
library(Ckmeans.1d.dp) # for xgb.ggplot.importance
xgb.ggplot.importance(importance_matrix, top_n = 15,
measure = "Gain")
# plot the trees from model using `xgb.plot.tree`
# xgb.plot.tree needs to be revised a little bit by adding `fontcolor="black"` in the `nodes <- DiagrammeR::create_node_df` line
# only show 1 tree as an example.
# Method 1
xgb.plot.tree(model = xg_mod, n_first_tree = 1, feature_names = colnames(X_train))
# Method 2
source("D:/OneDrive - nyu.edu/NYU Marron/R/xgb.plot.tree2.R")
library("DiagrammeR")
xgb.plot.tree2(model = xg_mod, n_first_tree = 1, feature_names = colnames(X_train))
# Project all trees on one tree and plot it: A huge plot
xgb.plot.multi.trees(model = xg_mod, n_first_tree = 1, feature_names = colnames(X_train),
features_var_keep = 3)
## https://medium.com/applied-data-science/new-r-package-the-xgboost-explainer-51dd7d1aa211
# install.packages("devtools")
library(devtools)
install_github("AppliedDataSciencePartners/xgboostExplainer")
#### THE XGBoost Explainer
library(xgboostExplainer)
explainer = buildExplainer(xg_mod, dtrain, type="regression", trees_idx = best_rmse_index)
pred.breakdown = explainPredictions(xg_mod, explainer, xgb.test.data)
cat('Breakdown Complete','\n')
weights = rowSums(pred.breakdown)
pred.xgb = 1/(1+exp(-weights))
cat(max(xgb.preds-pred.xgb),'\n')
idx_to_get = as.integer(802)
test[idx_to_get,-"left"]
showWaterfall(xg_mod, explainer, xgb.test.data, data.matrix(test[,-'left']) ,idx_to_get, type = "binary")
####### IMPACT AGAINST VARIABLE VALUE
plot(test[,satisfaction_level], pred.breakdown[,satisfaction_level], cex=0.4, pch=16, xlab = "Satisfaction Level", ylab = "Satisfaction Level impact on log-odds")
plot(test[,last_evaluation], pred.breakdown[,last_evaluation], cex=0.4, pch=16, xlab = "Last evaluation", ylab = "Last evaluation impact on log-odds")
cr <- colorRamp(c("blue", "red"))
plot(test[,last_evaluation], pred.breakdown[,last_evaluation], col = rgb(cr(round(test[,satisfaction_level])), max=255), cex=0.4, pch=16, xlab = "Last evaluation", ylab = "Last evaluation impact on log-odds")
# Summarize MSEs ----------------------------------------------------------
options(digits = 4)
(MSE <- data.frame(MSE_best.subset, MSE_Lasso,
MSE_rForest, MSE_boost, MSE_xgb))
# 07/09/2018
list.of.packages <- c("ggplot2", "data.table","plyr","QuantPsyc",
"glmnet","leaps","randomForest","gbm","caret","xgboost","Ckmeans.1d.dp",
"DiagrammeR", "knitr")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(data.table)    #
library(plyr)
library(ggplot2)
library(QuantPsyc)     # used to show standardized regression coefficients
library(glmnet)        # for Lasso
library(leaps)         # for best subset
library(randomForest)  # random forest
library(gbm)           # for Gradient boosting
library(caret)         # grid scan by train
library(xgboost)       # for Extreme Gradient boosting
library(Ckmeans.1d.dp) # for xgb.ggplot.importance in xgboost
library(DiagrammeR)    # for xgb.plot.tree in xgboost
library(knitr)
options(digits = 4)
options(tinytex.verbose = TRUE)
# Data Preparation using data.table -----------------------------
mydata <- fread("D:/OneDrive - nyu.edu/NYU Marron/Data/20180618_sdi 2.csv", stringsAsFactors = TRUE)
# clean variables names, remove "/".
names(mydata) <- gsub("/", "", names(mydata))
# create variable: Share_Temporary
# The dependent variable to be modeled: Share of temporary structure in slums
mydata[, Share_Temporary := CC7_Structures_Temporary / (CC7_Structures_Temporary + CC6_Structures_Permanent)]
# remove variables with over 20% NA, var_keeps those is.na < 20%
var_keep <- sapply(mydata, function(x) sum(is.na(x))) < dim(mydata)[1]*0.2
var_keep[length(var_keep)] <- TRUE # keep "Share_Temporary"
mydata[, names(mydata)[!var_keep]:= NULL]
mydata <- na.omit(mydata) # remove rest N.A.
# fix some format issue
Factor_List <- c("GG4_Toilets_Pay_Amount", "CC11_Population_Estimate", "CC10_Household_Size",
"CC12_Total_Population")
mydata[, (Factor_List) := lapply(.SD, as.numeric), .SDcols = Factor_List]
# remove useless factor
mydata[, c("Obs. Count", "City", "Country",
names(mydata)[grepl("Structure", names(mydata))],
names(mydata)[grepl("Ownership", names(mydata))]):=NULL]
# remove what are highly correlated to dependent variable
# divide training and test dataset
set.seed(123)
train_idx <- sample(dim(mydata)[1], dim(mydata)[1]* 0.6)
# The model.matrix() function is used in many regression packages for building
# an "X" matrix from data.
# need matrix for glmnet
X2 <- model.matrix(Share_Temporary~., data = mydata)
Y2 <- as.matrix(mydata[,"Share_Temporary"])
X_train <- X2[train_idx,]
X_test <- X2[-train_idx,]
Y_train <- Y2[train_idx]
Y_test <- Y2[-train_idx]
# merge back to df again, as df is required for regsubsets (best subset)
data_train <- data.frame(X2, Y2)[train_idx,]
mydata2 <- data.frame(X2, Y2)
library(xgboost)
# Matrix for xgb: dtrain
dtrain <- xgb.DMatrix(X_train, label = Y_train)
dtest <- xgb.DMatrix(X_test, label = Y_test)
# Randomize and bound
best_param <- list()
best_seednumber <- 1234
best_rmse <- Inf
best_rmse_index <- 0
time_now <- Sys.time()
set.seed(1234)
for (iter in 1:10) {
param <- list(objective = "reg:linear",  # For regression
eval_metric = "rmse",      # rmse is used for regression
max_depth = sample(6:10, 1),
eta = runif(1, .01, .1),   # Learning rate, default: 0.3
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:10, 1), # These two are important
max_delta_step = sample(5:10, 1)    # Can help to focus error
# into a small range.
)
cv.nround <-  1000
cv.nfold <-  5 # 5-fold cross-validation
seed.number  <-  sample.int(10000, 1) # set seed for the cv
set.seed(seed.number)
mdcv <- xgb.cv(data = dtrain, params = param,
nfold = cv.nfold, nrounds = cv.nround,
verbose = F, early_stopping_rounds = 8, maximize = FALSE)
min_rmse_index  <-  mdcv$best_iteration
min_rmse <-  mdcv$evaluation_log[min_rmse_index]$test_rmse_mean
if (min_rmse < best_rmse) {
best_rmse <- min_rmse
best_rmse_index <- min_rmse_index
best_seednumber <- seed.number
best_param <- param
}
}
Sys.time() - time_now
data.frame(best_param, best_rmse_index, best_rmse, best_seednumber)
# The best index (min_rmse_index) is the best "nround" in the model
nround <- best_rmse_index
set.seed(best_seednumber)
xg_mod <- xgboost(data = dtest, params = best_param, nround = nround, verbose = F)
# MSE
yhat_xg <- predict(xg_mod, dtest)
(MSE_xgb <- mean((yhat_xg - Y_test)^2))
importance_matrix <- xgb.importance(colnames(X_train), model = xg_mod)
# Use `xgb.plot.importance`, which create a _barplot_ or use `xgb.ggplot.importance`
library(Ckmeans.1d.dp) # for xgb.ggplot.importance
xgb.ggplot.importance(importance_matrix, top_n = 15, measure = "Gain")
library("DiagrammeR")
xgb.plot.tree(model = xg_mod, trees = 1, feature_names = colnames(X_train))
# xgb.plot.tree needs to be revised a little bit by adding `fontcolor ="black"` in the `nodes <- DiagrammeR::create_node_df` line
source("D:/OneDrive - nyu.edu/NYU Marron/R/xgb.plot.tree2.R")
xgb.plot.tree2(model = xg_mod, n_first_tree = 1, feature_names = colnames(X_train))
library(gbm)   # for Gradient boosting
library(caret) # scan the parameter grid using `train` function
time_now <- Sys.time()
para_grid <- expand.grid(n.trees = (20*c(50:100)),
shrinkage = c(0.1, 0.05, 0.01),
interaction.depth = c(1,3,5),
n.minobsinnode = 10)
trainControl <- trainControl(method = "cv", number = 10)
set.seed(123)
gbm_caret <- train(Share_Temporary ~ ., mydata[train_idx,],
distribution = "gaussian", method = "gbm",
trControl = trainControl, verbose = FALSE,
tuneGrid = para_grid, metric = "RMSE", bag.fraction = 0.75)
library(randomForest)
rf.fit <- randomForest(Share_Temporary ~ ., data = mydata2, subset = train_idx)
# Test on test data: mydata[-train_idx,]
yhat_bag <- predict(rf.fit, newdata = mydata2[-train_idx,])
(MSE_rForest <- mean((yhat_bag - Y_test)^2))
# The lasso model, used to feed the selected lambda to predict fitted value
lasso_mod <- glmnet(X_train, Y_train, alpha = 1)
# Use cross-validation to select the lambda
cv_lasso = cv.glmnet(X_train, Y_train, alpha=1) # Lasso regression
plot.cv.glmnet(cv_lasso)
# lambda selected by 1se rule
(best_lam <- cv_lasso$lambda.1se)
# Check prediction error in the testing dataset
lasso_pred <- predict(lasso_mod, s = best_lam, newx = X_test)
# The Mean squared error (MSE)
(MSE_Lasso <- mean((lasso_pred - Y_test)^2))
# coef_table is class 'dgCMatrix' of the selected coefficients for each lambda
coef_table <- coef(cv_lasso, s = cv_lasso$lambda.1se)
# Because there is the intercept on the first column, we use [coef_table@i + 1] to extract the names of coefficients (Dimnames) from class 'dgCMatrix', and [-1] in the end
var_list <- unlist(coef_table@Dimnames[[1]][coef_table@i + 1])
sdi_sub <- mydata[c(coef_table@Dimnames[[1]][coef_table@i + 1], "Share_Temporary")[-1]]
# coef_table is class 'dgCMatrix' of the selected coefficients for each lambda
coef_table <- coef(cv_lasso, s = cv_lasso$lambda.1se)
# Because there is the intercept on the first column, we use [coef_table@i + 1] to extract the names of coefficients (Dimnames) from class 'dgCMatrix', and [-1] in the end
var_list <- unlist(coef_table@Dimnames[[1]][coef_table@i + 1])
sdi_sub <- mydata2[c(coef_table@Dimnames[[1]][coef_table@i + 1], "Share_Temporary")[-1]]
reg_lasso_mod <- lm(data = sdi_sub, Share_Temporary~.)
reg_lasso_summary <- summary(reg_lasso_mod)
coef_table2 <- data.frame(reg_lasso_summary$coefficients, stb = c(0, lm.beta(reg_lasso_mod)))
coef_table2[order(abs(coef_table2$stb), decreasing = T),]
# the chosen model from cross-validation
reg.chosen4 <- lm(data = mydata2[train_idx, ], Share_Temporary~
FF11_Water_MonthlyCost  +
B14__resettled  +
Eviction_Threats    +
DD1_Location_Problemsflood_prone_area   +
FF1_8_Water_Sourcesshared_taps  +
DD1_Location_Problemscanal  +
FF1_8_Water_Sourceswater_tankers    +
B14__declared_legal_protected   +
FF1_8_Water_Sourcessprings  +
JJ1_Electricity_Availableyes    +
GG7_10_Toilet_Typesindividual_toilets   +
FF1_8_Water_Sourcesdams +
FF1_8_Water_Sourcesrivers   +
FF12_Water_CollectionTime30_minutes +
EE2A_Current_Eviction_Threat    +
DD1_Location_Problemsroad_side  +
DD1_Location_Problemsgarbage_dump
)
reg_chosen_bs <- summary(reg.chosen4)
coef_table_bs <- data.frame(b = reg_chosen_bs$coefficients, stb = c(0, lm.beta(reg.chosen4)))
coef_table_bs[order(abs(coef_table_bs$stb), decreasing = T),]
(MSE_best.subset <- mean((predict(reg.chosen4, mydata[-train_idx,]) - Y_test)^2))
(MSE_best.subset <- mean((predict(reg.chosen4, mydata2[-train_idx,]) - Y_test)^2))
(MSE <- data.frame(MSE_xgb, MSE_boost,  MSE_Lasso,
MSE_rForest, MSE_best.subset ))
# Data Preparation -----------------------------------------------------------
mydata <- fread("D:/OneDrive - nyu.edu/NYU Marron/Data/20180618_sdi 2.csv", stringsAsFactors = TRUE)
# clean variables names, remove "/".
names(mydata) <- gsub("/", "", names(mydata))
# create variable: Share_Temporary
# The dependent variable to be modeled: Share of temporary structure in slums
mydata[, Share_Temporary := CC7_Structures_Temporary / (CC7_Structures_Temporary + CC6_Structures_Permanent)]
# remove variables with over 20% NA, var_keeps those is.na < 20%
var_keep <- sapply(mydata, function(x) sum(is.na(x))) < dim(mydata)[1]*0.2
var_keep
# 4. Gradiant boosting ----------------------------------------------------
# Tuning Method: use `train` function from `caret` to scan for parameters.
library(gbm)   # for Gradiant boosting
library(caret) # scan the parameter grid using `train` function
time_now <- Sys.time()
para_grid <- expand.grid(n.trees = (20*c(50:100)),
shrinkage = c(0.1, 0.05, 0.01),
interaction.depth = c(1,3,5),
n.minobsinnode = 10)
trainControl <- trainControl(method = "cv", number = 10)
set.seed(123)
gbm_caret <- train(Share_Temporary ~ ., mydata2[train_idx,],
distribution = "gaussian", method = "gbm",
trControl = trainControl, verbose = FALSE,
tuneGrid = para_grid, metric = "RMSE", bag.fraction = 0.75)
# The tuning parameters that give lowest MSE in training set CV.
gbm_caret$bestTune
yhat_boost <- predict(gbm_caret, mydata2[-train_idx,])
(MSE_boost <- mean((yhat_boost - Y_test)^2))
Sys.time() - time_now
# 4. Gradiant boosting ----------------------------------------------------
# Tuning Method: use `train` function from `caret` to scan for parameters.
library(gbm)   # for Gradiant boosting
library(caret) # scan the parameter grid using `train` function
time_now <- Sys.time()
para_grid <- expand.grid(n.trees = (20*c(50:100)),
shrinkage = 0.01,
interaction.depth = 5,
n.minobsinnode = 10)
trainControl <- trainControl(method = "cv", number = 10)
set.seed(123)
gbm_caret <- train(Share_Temporary ~ ., mydata2[train_idx,],
distribution = "gaussian", method = "gbm",
trControl = trainControl, verbose = FALSE,
tuneGrid = para_grid, metric = "RMSE", bag.fraction = 0.75)
# The tuning parameters that give lowest MSE in training set CV.
gbm_caret$bestTune
yhat_boost <- predict(gbm_caret, mydata2[-train_idx,])
(MSE_boost <- mean((yhat_boost - Y_test)^2))
Sys.time() - time_now
getwd()
setwd("D:/OneDrive/Blogdown/hugo-xmag")
library(blogdown)
build_site()
blogdown:::serve_site()
build_site()
build_site()
