install.packages("blogdown")
setwd("H:/Blogdown/hugo-xmag")
library(blogdown)
serve_site()
blogdown::install_hugo()
knitr::opts_chunk$set(echo = T, warning = FALSE, message = FALSE)
list.of.packages <- c("raster", "rgdal", "Hmisc", "plyr", "RColorBrewer")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library('raster')   # obtain raster from GIS image file, and plot
library('rgdal')    # readOGR: read ArcGIS vector maps into Spatial objects
library('Hmisc')    # cut2: cut vector into equal-length
library('plyr')     # join
library('RColorBrewer') # for `brewer.pal` in ggplot2
library('knitr')    # kable
options(digits = 4)
list.of.packages <- c("raster", "rgdal", "Hmisc", "plyr", "RColorBrewer")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library('raster')   # obtain raster from GIS image file, and plot
library('rgdal')    # readOGR: read ArcGIS vector maps into Spatial objects
library('Hmisc')    # cut2: cut vector into equal-length
library('plyr')     # join
library('RColorBrewer') # for `brewer.pal` in ggplot2
library('knitr')    # kable
options(digits = 4)
# Where are all the data files located:
parent_dir <- c("D:/OneDrive - nyu.edu/NYU Marron/180716_Draw Circle/Data/")
# Get all the folder names (names of the cities) in the directory, used to scan all the cities
city_list <- list.files(parent_dir)
# If use Hong Kong as an example
city1 <- city_list[6]
newdir <- paste(parent_dir, city1, sep = "")
image <- raster(paste(newdir, c("./city_urbFootprint_clp_t3.img"), sep = ""))
# A point that shows the center of the city
cbd <-  readOGR(dsn = newdir, layer = paste(city1, "_CBD_Project", sep=""))
cbdpoint <- SpatialPoints(cbd)
library(googledrive)
list.of.packages <- c("raster", "rgdal", "Hmisc", "plyr", "RColorBrewer", "googledrive")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library('raster')   # obtain raster from GIS image file, and plot
library('rgdal')    # readOGR: read ArcGIS vector maps into Spatial objects
library('Hmisc')    # cut2: cut vector into equal-length
library('plyr')     # join
library('RColorBrewer') # for `brewer.pal` in ggplot2
library('knitr')    # kable
options(digits = 4)
library(googledrive)
temp <- tempfile(fileext = ".zip")
dl <- drive_download(as_id("1z-aD2orN2k2BINkDD6whEhHFga_4HIu8"), path = temp, overwrite = TRUE)
out <- unzip(temp, exdir = tempdir())
image <- raster(out[1])
cbdpoint <- SpatialPoints(readOGR(dsn = paste(tempdir(),"\\Hong_Kong",sep = ""),
layer = "Hong_Kong_CBD_Project"))
library(googledrive)
library(googledrive)
options(httr_oauth_cache = F)
temp <- tempfile(fileext = ".zip")
dl <- drive_download(as_id("1z-aD2orN2k2BINkDD6whEhHFga_4HIu8"), path = temp, overwrite = TRUE)
out <- unzip(temp, exdir = tempdir())
image <- raster(out[1])
cbdpoint <- SpatialPoints(readOGR(dsn = paste(tempdir(),"\\Hong_Kong",sep = ""),
layer = "Hong_Kong_CBD_Project"))
# mydata_HK contains coordinate (x,y) and category (type)
mydata_HK <- as.data.frame(rasterToPoints(image))
names(mydata_HK) <- c("x", "y", "type")
head(mydata_HK)
# calculate distance to the cbd from every point
pts <- as.matrix(mydata_HK[,1:2])
mydata_HK$cbd_dist <- spDistsN1(pts, cbdpoint, longlat = F)
# library('Hmisc') # cut2
mydata_HK$ring <- as.numeric(cut2(mydata_HK$cbd_dist,g = 100)) # get 1:100
mydata_HK$type <- as.factor(mydata_HK$type)
mydata_HK$ring <- as.factor(mydata_HK$ring)
# Function to get saturation, as the raster have 7 layers, 1 to 3 belong to built-up area
get_sat <- function(x){
x <- as.factor(x)
# (1 + 2 + 3) / (1 + 2 + 3 + 4 + 5 + 6 + 7)
sum(x==1|x==2|x==3)/length(x)
}
# get saturation by rings
sat_output <- aggregate(mydata_HK$type, by = list(mydata_HK$ring), FUN = get_sat)
names(sat_output) <- c("ring", "ring_saturation")
# join back to mydata_HK2 so we can later plot by values of ring_saturation
mydata_HK2 <- join(mydata_HK, sat_output, by = "ring")
kable(head(mydata_HK2))
r1 <- rasterFromXYZ(mydata_HK2)
plot(r1)
# choose a color scale from `RColorBrewer`
color_scale <- brewer.pal(n = 10, name = "RdYlGn")
myPalette <- colorRampPalette(rev(color_scale)) # reverse the order so highly value ~ dark red
# set col and breaks to align color scale across figures
plot(r1$ring_saturation, col=myPalette(70), breaks = c(30:100)/100,
legend=FALSE,  main = city1)
city1 <-"Hong_Kong"
r1 <- rasterFromXYZ(mydata_HK2)
plot(r1)
# choose a color scale from `RColorBrewer`
color_scale <- brewer.pal(n = 10, name = "RdYlGn")
myPalette <- colorRampPalette(rev(color_scale)) # reverse the order so highly value ~ dark red
# set col and breaks to align color scale across figures
plot(r1$ring_saturation, col=myPalette(70), breaks = c(30:100)/100,
legend=FALSE,  main = city1)
plot(cbdpoint, add = TRUE, size = 3) # drawn on top of a map using `add = TRUE`
# if need to output the raster
# writeRaster(r1, paste(raster_dir, city1, sep = ""), format = "HFA", overwrite=TRUE)
# To preview the color panel:
# display.brewer.pal(n = 12, name = 'RdYlGn')
sat <- read.csv(file = "D:/OneDrive - nyu.edu/NYU Marron/180716_Draw Circle/180720_Ring Saturation100.csv")
sat$idx <- rep(c(1:100),10)
summary(sat$ring_saturation)
# linear regression smoothing
ggplot(sat, aes(x=idx, y=ring_saturation)) +
geom_point(size = 0.5, color = 'blue') +
geom_smooth(method = 'lm')+
theme_classic() +
geom_hline(yintercept = 0) +
scale_y_continuous(limits = c(0,1)) +
labs(x = "Equal-Area Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in the 100 Rings")
# sat <- read.csv(file = "D:/OneDrive - nyu.edu/NYU Marron/180716_Draw Circle/180720_Ring Saturation100.csv")
# https://drive.google.com/open?id=1DNyQLX0apRVWmRC1xKhpqZLE6SLcQF5p
id <- "1DNyQLX0apRVWmRC1xKhpqZLE6SLcQF5p" # google file ID
sat <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id))
sat$idx <- rep(c(1:100),10)
summary(sat$ring_saturation)
# linear regression smoothing
ggplot(sat, aes(x=idx, y=ring_saturation)) +
geom_point(size = 0.5, color = 'blue') +
geom_smooth(method = 'lm')+
theme_classic() +
geom_hline(yintercept = 0) +
scale_y_continuous(limits = c(0,1)) +
labs(x = "Equal-Area Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in the 100 Rings")
# plot all the points for ten cities
ggplot(sat, aes(x=idx, y=ring_saturation, color = city)) +
geom_point(size = 1)
# plot line with error bar
ggplot(Mean_byGroup, aes(x=idx, y=wm, ymin=CI_low, ymax=CI_high)) +
geom_point(size = 2, color = 'red') +
geom_errorbar (width=bar_width-0.1, lwd=1, position=position_dodge(bar_width))+
geom_path() +
labs(x = "Ten Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in Each Ring")+
theme_classic() +
scale_x_continuous(breaks = c(1:10))+
geom_hline(yintercept = 0)
sat$weight_blank <- 1
source("D:/NYU Marron/R/Get Weighted SE and CI.R")
Mean_byGroup <- get_WM_and_CI2(sat, "idx", "ring_saturation", "weight_blank")
bar_width <- 0.8
ggplot(Mean_byGroup, aes(x=idx, y=wm,
ymin=CI_low, ymax=CI_high)) +
geom_bar(stat='identity', position = position_dodge(), width = bar_width, alpha=0.8)+
geom_errorbar (width=bar_width-0.1, lwd=1, position=position_dodge(bar_width))+
labs(x = "Ten Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in Each Ring")+
theme_classic()  +
geom_hline(yintercept = 0)
sat$weight_blank <- 1
source("D:/NYU Marron/R/Get Weighted SE and CI.R")
source("D:/OneDrive - nyu.edu/NYU Marron/R/Get Weighted SE and CI.R")
Mean_byGroup <- get_WM_and_CI2(sat, "idx", "ring_saturation", "weight_blank")
bar_width <- 0.8
ggplot(Mean_byGroup, aes(x=idx, y=wm,
ymin=CI_low, ymax=CI_high)) +
geom_bar(stat='identity', position = position_dodge(), width = bar_width, alpha=0.8)+
geom_errorbar (width=bar_width-0.1, lwd=1, position=position_dodge(bar_width))+
labs(x = "Ten Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in Each Ring")+
theme_classic()  +
geom_hline(yintercept = 0)
# plot line with error bar
ggplot(Mean_byGroup, aes(x=idx, y=wm, ymin=CI_low, ymax=CI_high)) +
geom_point(size = 2, color = 'red') +
geom_errorbar (width=bar_width-0.1, lwd=1, position=position_dodge(bar_width))+
geom_path() +
labs(x = "Ten Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in Each Ring")+
theme_classic() +
scale_x_continuous(breaks = c(1:10))+
geom_hline(yintercept = 0)
# plot all the points for ten cities
ggplot(sat, aes(x=idx, y=ring_saturation, color = city)) +
geom_point(size = 1)
# plot all the points for ten cities
ggplot(sat, aes(x=idx, y=ring_saturation, color = city)) +
geom_point(size = 1)
# linear regression smoothing
ggplot(sat, aes(x=idx, y=ring_saturation)) +
geom_point(size = 0.5, color = 'blue') +
geom_smooth(method = 'lm')+
theme_classic() +
geom_hline(yintercept = 0) +
scale_y_continuous(limits = c(0,1)) +
labs(x = "Equal-Area Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in the 100 Rings")
# plot line with error bar
ggplot(Mean_byGroup, aes(x=idx, y=wm, ymin=CI_low, ymax=CI_high)) +
geom_point(size = 2, color = 'red') +
geom_errorbar (width=bar_width-0.1, lwd=1, position=position_dodge(bar_width))+
geom_path() +
labs(x = "Ten Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in Each Ring")+
theme_classic() +
scale_x_continuous(breaks = c(1:10))+
geom_hline(yintercept = 0)
ggplot(Mean_byGroup, aes(x=idx, y=wm,
ymin=CI_low, ymax=CI_high)) +
geom_bar(stat='identity', position = position_dodge(), width = bar_width, alpha=0.8)+
geom_errorbar (width=bar_width-0.1, lwd=1, position=position_dodge(bar_width))+
labs(x = "Ten Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in Each Ring")+
theme_classic()  +
geom_hline(yintercept = 0)
par(mar = rep(2,4), bty="n")
layout(matrix(c(1:10),ncol=2, byrow = T))
for (i in 1:10){
sat_sub <- subset(sat, city == city_list[i])
plot(x = sat_sub$idx, y = sat_sub$ring_saturation, type = "l",
xlab=c("Ring from CBD"), ylab =c("Built-up Area/Urban Extent"),
main = city_list[i])
}
ggplot(Mean_byGroup, aes(x=idx, y=wm,
ymin=CI_low, ymax=CI_high)) +
geom_bar(stat='identity', position = position_dodge(), width = bar_width, alpha=0.8)+
geom_errorbar (width=bar_width-0.1, lwd=1, position=position_dodge(bar_width))+
labs(x = "Ten Rings from CBD", y = "Average Built-up Area/Urban Extent") +
ggtitle("Average Saturation in Each Ring")+
theme_classic()  +
geom_hline(yintercept = 0)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# Data Preparation using data.table -----------------------------
# https://drive.google.com/open?id=1pHE8ktykKfBN2_yo8FNxYX_BFKp1S0SN
id <- "1pHE8ktykKfBN2_yo8FNxYX_BFKp1S0SN" # google file ID
mydata <- fread(sprintf("https://docs.google.com/uc?id=%s&export=download", id))
library(data.table)    #
library(plyr)
library(ggplot2)
library(QuantPsyc)     # used to show standardized regression coefficients
library(glmnet)        # for Lasso
library(leaps)         # for best subset
library(randomForest)  # random forest
library(gbm)           # for Gradient boosting
library(caret)         # grid scan by train
library(xgboost)       # for Extreme Gradient boosting
library(Ckmeans.1d.dp) # for xgb.ggplot.importance in xgboost
library(DiagrammeR)    # for xgb.plot.tree in xgboost
library(knitr)
options(digits = 4)
options(tinytex.verbose = TRUE)
mydata <- fread(sprintf("https://docs.google.com/uc?id=%s&export=download", id))
mydata <- fread(sprintf("https://docs.google.com/uc?id=%s&export=download", id),
stringsAsFactors = TRUE)
# clean variables names, remove "/".
names(mydata) <- gsub("/", "", names(mydata))
# create variable: Share_Temporary
# The dependent variable to be modeled: Share of temporary structure in slums
mydata[, Share_Temporary := CC7_Structures_Temporary / (CC7_Structures_Temporary + CC6_Structures_Permanent)]
# remove variables with over 20% NA, var_keeps those is.na < 20%
var_keep <- sapply(mydata, function(x) sum(is.na(x))) < dim(mydata)[1]*0.2
var_keep[length(var_keep)] <- TRUE # keep "Share_Temporary"
mydata[, names(mydata)[!var_keep]:= NULL]
mydata <- na.omit(mydata) # remove rest N.A.
# fix some format issue
Factor_List <- c("GG4_Toilets_Pay_Amount", "CC11_Population_Estimate", "CC10_Household_Size",
"CC12_Total_Population")
mydata[, (Factor_List) := lapply(.SD, as.numeric), .SDcols = Factor_List]
# remove useless factor
mydata[, c("Obs. Count", "City", "Country",
names(mydata)[grepl("Structure", names(mydata))],
names(mydata)[grepl("Ownership", names(mydata))]):=NULL]
# remove what are highly correlated to dependent variable
# divide training and test dataset
set.seed(123)
train_idx <- sample(dim(mydata)[1], dim(mydata)[1]* 0.6)
# The model.matrix() function is used in many regression packages for building
# an "X" matrix from data.
# need matrix for glmnet
X2 <- model.matrix(Share_Temporary~., data = mydata)
Y2 <- as.matrix(mydata[,"Share_Temporary"])
X_train <- X2[train_idx,]
X_test <- X2[-train_idx,]
Y_train <- Y2[train_idx]
Y_test <- Y2[-train_idx]
# merge back to df again, as df is required for regsubsets (best subset)
data_train <- data.frame(X2, Y2)[train_idx,]
mydata2 <- data.frame(X2, Y2)
library(xgboost)
# Matrix for xgb: dtrain
dtrain <- xgb.DMatrix(X_train, label = Y_train)
dtest <- xgb.DMatrix(X_test, label = Y_test)
# Randomize and bound
best_param <- list()
best_seednumber <- 1234
best_rmse <- Inf
best_rmse_index <- 0
time_now <- Sys.time()
set.seed(1234)
for (iter in 1:10) {
param <- list(objective = "reg:linear",  # For regression
eval_metric = "rmse",      # rmse is used for regression
max_depth = sample(6:10, 1),
eta = runif(1, .01, .1),   # Learning rate, default: 0.3
subsample = runif(1, .6, .9),
colsample_bytree = runif(1, .5, .8),
min_child_weight = sample(1:10, 1), # These two are important
max_delta_step = sample(5:10, 1)    # Can help to focus error
# into a small range.
)
cv.nround <-  1000
cv.nfold <-  5 # 5-fold cross-validation
seed.number  <-  sample.int(10000, 1) # set seed for the cv
set.seed(seed.number)
mdcv <- xgb.cv(data = dtrain, params = param,
nfold = cv.nfold, nrounds = cv.nround,
verbose = F, early_stopping_rounds = 8, maximize = FALSE)
min_rmse_index  <-  mdcv$best_iteration
min_rmse <-  mdcv$evaluation_log[min_rmse_index]$test_rmse_mean
if (min_rmse < best_rmse) {
best_rmse <- min_rmse
best_rmse_index <- min_rmse_index
best_seednumber <- seed.number
best_param <- param
}
}
Sys.time() - time_now
data.frame(best_param, best_rmse_index, best_rmse, best_seednumber)
# The best index (min_rmse_index) is the best "nround" in the model
nround <- best_rmse_index
set.seed(best_seednumber)
xg_mod <- xgboost(data = dtest, params = best_param, nround = nround, verbose = F)
# MSE
yhat_xg <- predict(xg_mod, dtest)
(MSE_xgb <- mean((yhat_xg - Y_test)^2))
importance_matrix <- xgb.importance(colnames(X_train), model = xg_mod)
# Use `xgb.plot.importance`, which create a _barplot_ or use `xgb.ggplot.importance`
library(Ckmeans.1d.dp) # for xgb.ggplot.importance
xgb.ggplot.importance(importance_matrix, top_n = 15, measure = "Gain")
best_param
best_seednumber
best_rmse
best_rmse_index
